{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "remove = ()\n",
    "\n",
    "train = fetch_20newsgroups(subset='train',categories=categories,\n",
    "                          shuffle=True,random_state=42,remove=remove)\n",
    "test = fetch_20newsgroups(subset='test',categories=categories,\n",
    "                          shuffle=True,random_state=42,remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "\n",
      "[1 3 2 0 2 0 2 1 2 1]\n",
      "\n",
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train['target_names'])\n",
    "print()\n",
    "print(train['target'][:10])\n",
    "print()\n",
    "print(train['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st document text length is : 1022\n",
      "1st document text length is : 249\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def size_mb(docs):\n",
    "    print(\"1st document text length is : {}\".format(len(docs[0].encode('utf-8'))) )\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(train.data)\n",
    "data_test_size_mb = size_mb(test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split a training set and a test set\n",
    "train_X , train_Y = train.data , train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If n_samples == 10000, storing X as a numpy array of type float32 would require 10000 x 100000 x 4 bytes = 4GB in RAM\n",
    "Fortunately, most values in X will be zeros since for a given document less than a couple thousands of distinct words will be used. \n",
    "For this reason we say that bags of words are typically high-dimensional sparse datasets. \n",
    "We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from the training data using a sparse vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From occurrences to frequencies\n",
    "divide the number of occurrences of each word in a document by the total number of words in the document: \n",
    "these new features are called tf for Term Frequencies.\n",
    "\n",
    "to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”.\n",
    "Both tf and tf–idf can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train.data)  # the fit(..) method to fit our estimator to the data and \n",
    "                                                #secondly the transform(..) method to transform our count-matrix to a tf-idf representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2034x33809 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 224893 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_train) )\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 33809)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #33809 unique words(except stop words and low count words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '000005102000',\n",
       " '000021',\n",
       " '000062david42',\n",
       " '0000vec',\n",
       " '0001']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
